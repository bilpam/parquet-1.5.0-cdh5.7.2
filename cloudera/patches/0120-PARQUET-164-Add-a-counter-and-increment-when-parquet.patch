From b37cb3a0cf266cc675a0e2418dadfa6d6e8a298f Mon Sep 17 00:00:00 2001
From: dongche1 <dong1.chen@intel.com>
Date: Tue, 19 May 2015 11:26:07 -0700
Subject: [PATCH 120/176] PARQUET-164: Add a counter and increment when
 parquet memory manager kicks in

Add a counter for writers, and increment it when memory manager scaling down row group size.

Hive could use this counter to warn users.

Author: dongche1 <dong1.chen@intel.com>
Author: dongche <dong1.chen@intel.com>
Author: root <root@bdpe15.sh.intel.com>

Closes #120 from dongche/PARQUET-164 and squashes the following commits:

9bcb1ba [dongche] Remove stats, and change returned callbacks map unmodifiable
3cbbeb9 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164
bdef233 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164
780be6d [root] revert change about callable and address comments
11f9163 [dongche1] Merge remote branch 'upstream/master' into PARQUET-164
55549a5 [dongche1] Use callable and strict registerScallCallBack method.
74054aa [dongche1] Use Runnable as a generic callback
8782a02 [dongche1] Add a callback mechanism instead of shims. And rebase trunk
b138b7f [dongche1] Merge remote branch 'upstream/master' into PARQUET-164
93a4678 [dongche1] PARQUET-164: Add a counter and increment when parquet memory manager kicks in

Conflicts:
	parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java
Resolution:
    Fixed imports.
---
 .../main/java/parquet/hadoop/MemoryManager.java    |   42 +++++++++++++++++++-
 .../java/parquet/hadoop/ParquetOutputFormat.java   |    2 +-
 .../java/parquet/hadoop/TestMemoryManager.java     |   28 ++++++++++++-
 3 files changed, 69 insertions(+), 3 deletions(-)

diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java b/parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java
index 9724868..874e9df 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java
@@ -20,8 +20,10 @@ package parquet.hadoop;
 
 import parquet.Log;
 import parquet.ParquetRuntimeException;
+import parquet.Preconditions;
 
 import java.lang.management.ManagementFactory;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
@@ -47,6 +49,8 @@ public class MemoryManager {
   private final long minMemoryAllocation;
   private final Map<InternalParquetRecordWriter, Long> writerList = new
       HashMap<InternalParquetRecordWriter, Long>();
+  private final Map<String, Runnable> callBacks = new HashMap<String, Runnable>();
+  private double scale = 1.0;
 
   public MemoryManager(float ratio, long minAllocation) {
     checkRatio(ratio);
@@ -100,7 +104,6 @@ public class MemoryManager {
    */
   private void updateAllocation() {
     long totalAllocations = 0;
-    double scale;
     for (Long allocation : writerList.values()) {
       totalAllocations += allocation;
     }
@@ -112,6 +115,10 @@ public class MemoryManager {
           "Total allocation exceeds %.2f%% (%,d bytes) of heap memory\n" +
           "Scaling row group sizes to %.2f%% for %d writers",
           100*memoryPoolRatio, totalMemoryPool, 100*scale, writerList.size()));
+      for (Runnable callBack : callBacks.values()) {
+        // we do not really want to start a new thread here.
+        callBack.run();
+      }
     }
 
     int maxColCount = 0;
@@ -155,4 +162,37 @@ public class MemoryManager {
   float getMemoryPoolRatio() {
     return memoryPoolRatio;
   }
+
+  /**
+   * Register callback and deduplicate it if any.
+   * @param callBackName the name of callback. It should be identical.
+   * @param callBack the callback passed in from upper layer, such as Hive.
+   */
+  public void registerScaleCallBack(String callBackName, Runnable callBack) {
+    Preconditions.checkNotNull(callBackName, "callBackName");
+    Preconditions.checkNotNull(callBack, "callBack");
+
+    if (callBacks.containsKey(callBackName)) {
+      throw new IllegalArgumentException("The callBackName " + callBackName +
+          " is duplicated and has been registered already.");
+    } else {
+      callBacks.put(callBackName, callBack);
+    }
+  }
+
+  /**
+   * Get the registered callbacks.
+   * @return
+   */
+  Map<String, Runnable> getScaleCallBacks() {
+    return Collections.unmodifiableMap(callBacks);
+  }
+
+  /**
+   * Get the internal scale value of MemoryManger
+   * @return
+   */
+  double getScale() {
+    return scale;
+  }
 }
diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java
index 9bfa5e7..07ba458 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java
@@ -347,7 +347,7 @@ public class ParquetOutputFormat<T> extends FileOutputFormat<Void, T> {
    */
   private static MemoryManager memoryManager;
 
-  static MemoryManager getMemoryManager() {
+  public static MemoryManager getMemoryManager() {
     return memoryManager;
   }
 }
diff --git a/parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java b/parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java
index aae499b..5ee0e3f 100644
--- a/parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java
+++ b/parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java
@@ -48,6 +48,8 @@ public class TestMemoryManager {
   int rowGroupSize;
   ParquetOutputFormat parquetOutputFormat;
   CompressionCodecName codec;
+  int counter = 0;
+  boolean firstRegister = true;
 
   @Before
   public void setUp() {
@@ -87,12 +89,36 @@ public class TestMemoryManager {
     //Verify the memory pool
     Assert.assertEquals("memory pool size is incorrect.", expectPoolSize,
         parquetOutputFormat.getMemoryManager().getTotalMemoryPool());
+
+    //Verify Callback mechanism
+    Assert.assertEquals("counter calculated by callback is incorrect.", 1, counter);
+    Assert.assertEquals("CallBack is duplicated.", 1, parquetOutputFormat.getMemoryManager()
+        .getScaleCallBacks().size());
   }
 
   private RecordWriter createWriter(int index) throws Exception{
     Path file = new Path("target/test/", "parquet" + index);
     parquetOutputFormat = new ParquetOutputFormat(new GroupWriteSupport());
-    return parquetOutputFormat.getRecordWriter(conf, file, codec);
+    RecordWriter writer = parquetOutputFormat.getRecordWriter(conf, file, codec);
+    try {
+      parquetOutputFormat.getMemoryManager().registerScaleCallBack("increment-test-counter",
+          new Runnable() {
+            @Override
+            public void run() {
+              counter++;
+            }
+          });
+      if (!firstRegister) {
+        Assert.fail("Duplicated registering callback should throw duplicates exception.");
+      }
+      firstRegister = false;
+    } catch (IllegalArgumentException e) {
+      if (firstRegister) {
+        Assert.fail("Registering the same callback first time should succeed.");
+      }
+    }
+
+    return writer;
   }
 
   private void verifyRowGroupSize(int expectRowGroupSize) {
-- 
1.7.9.5

