From 5d286eecc1961be0a79786145799de08427ec092 Mon Sep 17 00:00:00 2001
From: Thomas Friedrich <tfriedr@us.ibm.com>
Date: Fri, 3 Jul 2015 10:53:22 -0700
Subject: [PATCH 150/176] PARQUET-324: row count incorrect if data file has
 more than 2^31 rows

Need to change numRows counter from int to long to account for input files with more than 2^31 rows.

Author: Thomas Friedrich <tfriedr@us.ibm.com>

Closes #233 from tfriedr/parquet-324 and squashes the following commits:

0120205 [Thomas Friedrich] change numRows from int to long
---
 .../format/converter/ParquetMetadataConverter.java |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java b/parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java
index aa24022..592ef6b 100644
--- a/parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java
+++ b/parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java
@@ -89,7 +89,7 @@ public class ParquetMetadataConverter {
   public FileMetaData toParquetMetadata(int currentVersion, ParquetMetadata parquetMetadata) {
     List<BlockMetaData> blocks = parquetMetadata.getBlocks();
     List<RowGroup> rowGroups = new ArrayList<RowGroup>();
-    int numRows = 0;
+    long numRows = 0;
     for (BlockMetaData block : blocks) {
       numRows += block.getRowCount();
       addRowGroup(parquetMetadata, rowGroups, block);
-- 
1.7.9.5

