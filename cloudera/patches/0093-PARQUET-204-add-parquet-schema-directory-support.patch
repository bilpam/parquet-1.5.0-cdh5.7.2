From 0c86374a625d9d593371635fab57742529d80c3f Mon Sep 17 00:00:00 2001
From: Neville Li <neville@spotify.com>
Date: Tue, 24 Mar 2015 16:06:26 -0700
Subject: [PATCH 093/176] PARQUET-204: add parquet-schema directory support

Author: Neville Li <neville@spotify.com>

Closes #136 from nevillelyh/neville/PARQUET-204 and squashes the following commits:

633829b [Neville Li] PARQUET-204: add parquet-schema directory support
7aa8581 [Neville Li] PARQUET-203: consolidate PathFilter for hidden files
---
 .../java/parquet/hadoop/ParquetFileReader.java     |    9 ++----
 .../java/parquet/hadoop/ParquetInputFormat.java    |   10 ++----
 .../main/java/parquet/hadoop/ParquetReader.java    |    9 ++----
 .../src/main/java/parquet/hadoop/PrintFooter.java  |    9 ++----
 .../java/parquet/hadoop/util/HiddenFileFilter.java |   33 ++++++++++++++++++++
 .../java/parquet/hadoop/TestParquetFileWriter.java |    9 ++----
 .../parquet/tools/command/ShowSchemaCommand.java   |   19 ++++++++++-
 7 files changed, 61 insertions(+), 37 deletions(-)
 create mode 100644 parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java

diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java
index de94b12..99f52c8 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java
@@ -52,7 +52,6 @@ import org.apache.hadoop.fs.FSDataInputStream;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.PathFilter;
 
 import parquet.Log;
 import parquet.bytes.BytesInput;
@@ -75,6 +74,7 @@ import parquet.hadoop.ColumnChunkPageReadStore.ColumnChunkPageReader;
 import parquet.hadoop.metadata.BlockMetaData;
 import parquet.hadoop.metadata.ColumnChunkMetaData;
 import parquet.hadoop.metadata.ParquetMetadata;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.hadoop.util.counters.BenchmarkCounter;
 import parquet.io.ParquetDecodingException;
 
@@ -299,12 +299,7 @@ public class ParquetFileReader implements Closeable {
   private static List<FileStatus> listFiles(Configuration conf, FileStatus fileStatus) throws IOException {
     if (fileStatus.isDir()) {
       FileSystem fs = fileStatus.getPath().getFileSystem(conf);
-      FileStatus[] list = fs.listStatus(fileStatus.getPath(), new PathFilter() {
-        @Override
-        public boolean accept(Path p) {
-          return !p.getName().startsWith("_") && !p.getName().startsWith(".");
-        }
-      });
+      FileStatus[] list = fs.listStatus(fileStatus.getPath(), HiddenFileFilter.INSTANCE);
       List<FileStatus> result = new ArrayList<FileStatus>();
       for (FileStatus sub : list) {
         result.addAll(listFiles(conf, sub));
diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java
index 5243a4c..449b8d1 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java
@@ -65,6 +65,7 @@ import parquet.hadoop.metadata.GlobalMetaData;
 import parquet.hadoop.metadata.ParquetMetadata;
 import parquet.hadoop.util.ConfigurationUtil;
 import parquet.hadoop.util.ContextUtil;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.hadoop.util.SerializationUtil;
 import parquet.io.ParquetDecodingException;
 import parquet.schema.MessageType;
@@ -340,7 +341,7 @@ public class ParquetInputFormat<T> extends FileInputFormat<Void, T> {
       if (file.isDir()) {
         Path p = file.getPath();
         FileSystem fs = p.getFileSystem(conf);
-        staticAddInputPathRecursively(result, fs, p, hiddenFileFilter);
+        staticAddInputPathRecursively(result, fs, p, HiddenFileFilter.INSTANCE);
       } else {
         result.add(file);
       }
@@ -361,13 +362,6 @@ public class ParquetInputFormat<T> extends FileInputFormat<Void, T> {
     }
   }
 
-  private static final PathFilter hiddenFileFilter = new PathFilter(){
-    public boolean accept(Path p){
-      String name = p.getName();
-      return !name.startsWith("_") && !name.startsWith(".");
-    }
-  };
-
   /**
    * @param jobContext the current job context
    * @return the footers for the files
diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java
index 4231ae4..7c3ecbb 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java
@@ -31,13 +31,13 @@ import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 
-import org.apache.hadoop.fs.PathFilter;
 import parquet.filter.UnboundRecordFilter;
 import parquet.filter2.compat.FilterCompat;
 import parquet.filter2.compat.FilterCompat.Filter;
 import parquet.filter2.compat.RowGroupFilter;
 import parquet.hadoop.api.ReadSupport;
 import parquet.hadoop.metadata.BlockMetaData;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.schema.MessageType;
 
 /**
@@ -110,12 +110,7 @@ public class ParquetReader<T> implements Closeable {
     this.conf = conf;
 
     FileSystem fs = file.getFileSystem(conf);
-    List<FileStatus> statuses = Arrays.asList(fs.listStatus(file, new PathFilter() {
-      @Override
-      public boolean accept(Path p) {
-        return !p.getName().startsWith("_") && !p.getName().startsWith(".");
-      }
-    }));
+    List<FileStatus> statuses = Arrays.asList(fs.listStatus(file, HiddenFileFilter.INSTANCE));
     List<Footer> footers = ParquetFileReader.readAllFootersInParallelUsingSummaryFiles(conf, statuses, false);
     this.footersIterator = footers.iterator();
   }
diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java b/parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java
index 5f1d271..0728f8f 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java
@@ -42,7 +42,6 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.PathFilter;
 
 import parquet.column.ColumnDescriptor;
 import parquet.column.Encoding;
@@ -50,6 +49,7 @@ import parquet.column.statistics.Statistics;
 import parquet.hadoop.metadata.BlockMetaData;
 import parquet.hadoop.metadata.ColumnChunkMetaData;
 import parquet.hadoop.metadata.ParquetMetadata;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.io.ParquetDecodingException;
 import parquet.schema.MessageType;
 
@@ -82,12 +82,7 @@ public class PrintFooter {
       List<FileStatus> statuses;
       if (fileStatus.isDir()) {
         System.out.println("listing files in " + fileStatus.getPath());
-        statuses = Arrays.asList(fs.listStatus(fileStatus.getPath(), new PathFilter() {
-          @Override
-          public boolean accept(Path path) {
-            return !path.getName().startsWith("_");
-          }
-        }));
+        statuses = Arrays.asList(fs.listStatus(fileStatus.getPath(), HiddenFileFilter.INSTANCE));
       } else {
         statuses = new ArrayList<FileStatus>();
         statuses.add(fileStatus);
diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java b/parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java
new file mode 100644
index 0000000..0bc2de6
--- /dev/null
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java
@@ -0,0 +1,33 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package parquet.hadoop.util;
+
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.PathFilter;
+
+public class HiddenFileFilter implements PathFilter {
+  public static final HiddenFileFilter INSTANCE = new HiddenFileFilter();
+
+  private HiddenFileFilter() {}
+
+  @Override
+  public boolean accept(Path p) {
+    return !p.getName().startsWith("_") && !p.getName().startsWith(".");
+  }
+}
diff --git a/parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java b/parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java
index 4a81b85..e991bd2 100644
--- a/parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java
+++ b/parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java
@@ -23,7 +23,6 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.PathFilter;
 import org.junit.Test;
 import parquet.Log;
 import parquet.bytes.BytesInput;
@@ -37,6 +36,7 @@ import parquet.column.statistics.BinaryStatistics;
 import parquet.column.statistics.LongStatistics;
 import parquet.format.Statistics;
 import parquet.hadoop.metadata.*;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.io.api.Binary;
 import parquet.schema.MessageType;
 import parquet.schema.MessageTypeParser;
@@ -325,12 +325,7 @@ public class TestParquetFileWriter {
 
     validateFooters(metadata);
 
-    footers = ParquetFileReader.readAllFootersInParallelUsingSummaryFiles(configuration, Arrays.asList(fs.listStatus(testDirPath, new PathFilter() {
-      @Override
-      public boolean accept(Path p) {
-        return !p.getName().startsWith("_");
-      }
-    })), false);
+    footers = ParquetFileReader.readAllFootersInParallelUsingSummaryFiles(configuration, Arrays.asList(fs.listStatus(testDirPath, HiddenFileFilter.INSTANCE)), false);
     validateFooters(footers);
 
     fs.delete(metadataFile.getPath(), false);
diff --git a/parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java b/parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java
index 6f55b61..079e09d 100644
--- a/parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java
+++ b/parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java
@@ -25,10 +25,13 @@ import org.apache.commons.cli.Option;
 import org.apache.commons.cli.OptionBuilder;
 import org.apache.commons.cli.Options;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 
 import parquet.hadoop.ParquetFileReader;
 import parquet.hadoop.metadata.ParquetMetadata;
+import parquet.hadoop.util.HiddenFileFilter;
 import parquet.schema.MessageType;
 import parquet.tools.Main;
 import parquet.tools.util.MetadataUtils;
@@ -73,7 +76,21 @@ public class ShowSchemaCommand extends ArgsOnlyCommand {
     String input = args[0];
 
     Configuration conf = new Configuration();
-    ParquetMetadata metaData = ParquetFileReader.readFooter(conf, new Path(input));
+    ParquetMetadata metaData;
+
+    Path path = new Path(input);
+    FileSystem fs = path.getFileSystem(conf);
+    Path file;
+    if (fs.isDirectory(path)) {
+      FileStatus[] statuses = fs.listStatus(path, HiddenFileFilter.INSTANCE);
+      if (statuses.length == 0) {
+        throw new RuntimeException("Directory " + path.toString() + " is empty");
+      }
+      file = statuses[0].getPath();
+    } else {
+      file = path;
+    }
+    metaData = ParquetFileReader.readFooter(conf, file);
     MessageType schema = metaData.getFileMetaData().getSchema();
 
     Main.out.println(schema);
-- 
1.7.9.5

